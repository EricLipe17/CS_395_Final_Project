{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import localtime, strftime\n",
    "from PUBG_Batching_Class import PUBG_Data_Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing Data:\n",
    "# print(\"Importing Data:\")\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# train_data = pd.read_csv(\"D:\\\\PUBG_preprocessed_training_data.csv\")\n",
    "# validation_data = pd.read_csv(\"D:\\\\PUBG_preprocessed_validation_data.csv\")\n",
    "\n",
    "# print(\"\\nMapping Validation Data:\")\n",
    "# validation_targets = pd.DataFrame(validation_data['winPlacePerc'])\n",
    "# validation_inputs = validation_data.drop([\"Unnamed: 0\", \"Id\", \"winPlacePerc\"], axis=1)\n",
    "\n",
    "# print(\"\\nMapping Train Data\")\n",
    "# train_IDS = pd.DataFrame(train_data[\"Id\"])\n",
    "# train_targets = pd.DataFrame(train_data[\"winPlacePerc\"])\n",
    "# train_inputs = train_data.drop([\"Unnamed: 0\", \"Id\", \"winPlacePerc\"], axis=1)\n",
    "\n",
    "# print(\"\\nBegin Training: \")\n",
    "batch_size = 100\n",
    "\n",
    "train_data = PUBG_Data_Reader('PUBG_preprocessed_training_data.csv', batch_size)\n",
    "validation_data = PUBG_Data_Reader('PUBG_preprocessed_validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PUBG_Batching_Class.PUBG_Data_Reader at 0x221af985b38>,\n",
       " <PUBG_Batching_Class.PUBG_Data_Reader at 0x221af6be0b8>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Constants\n",
    "input_size = 66\n",
    "output_size = 1\n",
    "hidden_layer_size = 50\n",
    "# Thus far, Relu performs better than all activations hitting a abs_mean_loss = 0.07180 with 5 hidden layers.\n",
    "\n",
    "# Building the Model\n",
    "tf.reset_default_graph()\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, input_size])\n",
    "targets = tf.placeholder(tf.float32, [None, output_size])\n",
    "\n",
    "weights_1 = tf.get_variable(\"Weights_1\", [input_size, hidden_layer_size])\n",
    "biases_1 = tf.get_variable(\"Biases_1\", [hidden_layer_size])\n",
    "outputs_1 = tf.nn.relu(tf.matmul(inputs, weights_1) + biases_1)\n",
    "\n",
    "weights_2 = tf.get_variable(\"Weights_2\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_2 = tf.get_variable(\"Biases_2\", [hidden_layer_size])\n",
    "outputs_2 = tf.nn.relu(tf.matmul(outputs_1, weights_2) + biases_2)\n",
    "\n",
    "weights_3 = tf.get_variable(\"Weights_3\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_3 = tf.get_variable(\"Biases_3\", [hidden_layer_size])\n",
    "outputs_3 = tf.nn.relu(tf.matmul(outputs_2, weights_3) + biases_3)\n",
    "\n",
    "weights_4 = tf.get_variable(\"Weights_4\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_4 = tf.get_variable(\"Biases_4\", [hidden_layer_size])\n",
    "outputs_4 = tf.nn.relu(tf.matmul(outputs_3, weights_4) + biases_4)\n",
    "\n",
    "weights_5 = tf.get_variable(\"Weights_5\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_5 = tf.get_variable(\"Biases_5\", [hidden_layer_size])\n",
    "outputs_5 = tf.nn.relu(tf.matmul(outputs_4, weights_5) + biases_5)\n",
    "\n",
    "weights_6 = tf.get_variable(\"Weights_6\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_6 = tf.get_variable(\"Biases_6\", [hidden_layer_size])\n",
    "outputs_6 = tf.nn.relu(tf.matmul(outputs_5, weights_6) + biases_6)\n",
    "\n",
    "weights_7 = tf.get_variable(\"Weights_7\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_7 = tf.get_variable(\"Biases_7\", [hidden_layer_size])\n",
    "outputs_7 = tf.nn.relu(tf.matmul(outputs_6, weights_7) + biases_7)\n",
    "\n",
    "weights_8 = tf.get_variable(\"Weights_8\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_8 = tf.get_variable(\"Biases_8\", [hidden_layer_size])\n",
    "outputs_8 = tf.nn.relu(tf.matmul(outputs_7, weights_8) + biases_8)\n",
    "\n",
    "weights_9 = tf.get_variable(\"Weights_9\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_9 = tf.get_variable(\"Biases_9\", [hidden_layer_size])\n",
    "outputs_9 = tf.nn.relu(tf.matmul(outputs_8, weights_9) + biases_9)\n",
    "\n",
    "weights_10 = tf.get_variable(\"Weights_10\", [hidden_layer_size, hidden_layer_size])\n",
    "biases_10 = tf.get_variable(\"Biases_10\", [hidden_layer_size])\n",
    "outputs_10 = tf.nn.relu(tf.matmul(outputs_9, weights_10) + biases_10)\n",
    "\n",
    "# weights_11 = tf.get_variable(\"Weights_11\", [hidden_layer_size, hidden_layer_size])\n",
    "# biases_11 = tf.get_variable(\"Biases_11\", [hidden_layer_size])\n",
    "# outputs_11 = tf.nn.relu(tf.matmul(outputs_10, weights_11) + biases_11)\n",
    "\n",
    "# weights_12 = tf.get_variable(\"Weights_12\", [hidden_layer_size, hidden_layer_size])\n",
    "# biases_12 = tf.get_variable(\"Biases_12\", [hidden_layer_size])\n",
    "# outputs_12 = tf.nn.relu(tf.matmul(outputs_11, weights_12) + biases_12)\n",
    "\n",
    "# weights_13 = tf.get_variable(\"Weights_13\", [hidden_layer_size, hidden_layer_size])\n",
    "# biases_13 = tf.get_variable(\"Biases_13\", [hidden_layer_size])\n",
    "# outputs_13 = tf.nn.relu(tf.matmul(outputs_12, weights_13) + biases_13)\n",
    "\n",
    "# weights_14 = tf.get_variable(\"Weights_14\", [hidden_layer_size, hidden_layer_size])\n",
    "# biases_14 = tf.get_variable(\"Biases_14\", [hidden_layer_size])\n",
    "# outputs_14 = tf.nn.relu(tf.matmul(outputs_13, weights_14) + biases_14)\n",
    "\n",
    "# weights_15 = tf.get_variable(\"Weights_15\", [hidden_layer_size, hidden_layer_size])\n",
    "# biases_15 = tf.get_variable(\"Biases_15\", [hidden_layer_size])\n",
    "# outputs_15 = tf.nn.relu(tf.matmul(outputs_14, weights_15) + biases_15)\n",
    "\n",
    "# weights_16 = tf.get_variable(\"Weights_16\", [hidden_layer_size, hidden_layer_size])\n",
    "# biases_16 = tf.get_variable(\"Biases_16\", [hidden_layer_size])\n",
    "# outputs_16 = tf.nn.relu(tf.matmul(outputs_15, weights_16) + biases_16)\n",
    "\n",
    "# weights_17 = tf.get_variable(\"Weights_17\", [hidden_layer_size, hidden_layer_size])\n",
    "# biases_17 = tf.get_variable(\"Biases_17\", [hidden_layer_size])\n",
    "# outputs_17 = tf.nn.relu(tf.matmul(outputs_16, weights_17) + biases_17)\n",
    "\n",
    "# weights_18 = tf.get_variable(\"Weights_18\", [hidden_layer_size, hidden_layer_size])\n",
    "# biases_18 = tf.get_variable(\"Biases_18\", [hidden_layer_size])\n",
    "# outputs_18 = tf.nn.relu(tf.matmul(outputs_17, weights_18) + biases_18)\n",
    "\n",
    "# weights_19 = tf.get_variable(\"Weights_19\", [hidden_layer_size, hidden_layer_size])\n",
    "# biases_19 = tf.get_variable(\"Biases_19\", [hidden_layer_size])\n",
    "# outputs_19 = tf.nn.relu(tf.matmul(outputs_18, weights_19) + biases_19)\n",
    "\n",
    "# weights_20 = tf.get_variable(\"Weights_20\", [hidden_layer_size, hidden_layer_size])\n",
    "# biases_20 = tf.get_variable(\"Biases_20\", [hidden_layer_size])\n",
    "# outputs_20 = tf.nn.relu(tf.matmul(outputs_19, weights_20) + biases_20)\n",
    "\n",
    "weights_final = tf.get_variable(\"Weights_Final\", [hidden_layer_size, output_size])\n",
    "biases_final = tf.get_variable(\"Biases_Final\", [output_size])\n",
    "output = tf.nn.relu(tf.matmul(outputs_10, weights_final) + biases_final)\n",
    "\n",
    "mean_loss = tf.losses.mean_squared_error(labels=targets, predictions=output)\n",
    "abs_mean_loss = tf.reduce_mean(tf.losses.absolute_difference(labels=targets, predictions=output))\n",
    "\n",
    "optimize = tf.train.AdamOptimizer(learning_rate=0.001).minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2019-04-14 11:21:08\n",
      "Running Algorithm: \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (100,) for Tensor 'Placeholder_1:0', which has shape '(?, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a8bb78a3f5b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         _, batch_loss, batch_abs_mean_loss = sess.run([optimize, mean_loss, abs_mean_loss],\n\u001b[1;32m---> 29\u001b[1;33m                                 feed_dict={inputs: input_batch, targets: target_batch})\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mcurr_square_epoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1128\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1129\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (100,) for Tensor 'Placeholder_1:0', which has shape '(?, 1)'"
     ]
    }
   ],
   "source": [
    "# Keeping track of the time pre-training:\n",
    "print(\"Start Time: \" + str(strftime(\"%Y-%m-%d %H:%M:%S\", localtime())))\n",
    "\n",
    "# Initializing the session for the Model to run:\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "initializer = tf.global_variables_initializer()\n",
    "\n",
    "prev_validation_loss = 9999999\n",
    "\n",
    "sess.run(initializer)\n",
    "print(\"Running Algorithm: \")\n",
    "epoch = 1\n",
    "while True:\n",
    "#     _, absolute_loss, squared_loss = sess.run([optimize, abs_mean_loss, mean_loss], feed_dict={inputs: train_inputs, targets: train_targets})\n",
    "\n",
    "#     validation_absolute_loss = sess.run(abs_mean_loss, feed_dict={inputs: validation_inputs, targets: validation_targets})\n",
    "    \n",
    "    curr_square_epoch_loss = 0.\n",
    "    curr_abs_epoch_loss = 0.\n",
    "    \n",
    "    for input_batch, target_batch in train_data:\n",
    "        _, batch_loss, batch_abs_mean_loss = sess.run([optimize, mean_loss, abs_mean_loss],\n",
    "                                feed_dict={inputs: input_batch, targets: target_batch})\n",
    "        \n",
    "        curr_square_epoch_loss += batch_loss\n",
    "        curr_abs_epoch_loss += batch_abs_mean_loss\n",
    "    \n",
    "    curr_square_epoch_loss /= train_data.batch_count\n",
    "    curr_abs_epoch_loss /= train_data.batch_count\n",
    "    \n",
    "    validation_square_loss = 0.\n",
    "    validation_absolute_loss = 0.\n",
    "    \n",
    "    for input_batch, target_batch in validation_data:\n",
    "        validation_square_loss, validation_absolute_loss = sess.run([mean_loss, abs_mean_loss],\n",
    "                     feed_dict={inputs: input_batch, targets: target_batch})\n",
    "    \n",
    "    print('Epoch ' +str(epoch) +\n",
    "         '. Training Loss: ' + '{0:.10f}'.format(curr_square_epoch_loss) +\n",
    "         '. Training Abs Loss: ' + '{0:.10f}' .format(curr_abs_epoch_loss) +\n",
    "         '. Validation Loss: ' + '{0:.10f}'.format(validation_square_loss) +\n",
    "         '. Validation Abs Loss: ' + '{0:.10f}'.format(validation_absolute_loss))\n",
    "\n",
    "    if validation_absolute_loss > prev_validation_loss:\n",
    "        print(\"Early Stopping Activated.\\n\")\n",
    "        break\n",
    "\n",
    "    prev_validation_loss = validation_absolute_loss\n",
    "    epoch += 1\n",
    "\n",
    "print(\"End of Training.\")\n",
    "print(\"End Time: \" + str(strftime(\"%Y-%m-%d %H:%M:%S\", localtime())))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(layers.Dense(50, activation = \"tanh\", input_shape=(train_inputs.shape[1],)))\n",
    "# model.add(layers.Dense(50, activation = \"tanh\"))\n",
    "# model.add(layers.Dense(50, activation = \"tanh\"))\n",
    "# model.add(layers.Dense(50, activation = \"tanh\"))\n",
    "# model.add(layers.Dense(1, activation = \"tanh\"))\n",
    "# model.compile(optimizer = \"adam\", loss = \"logcosh\", metrics = [\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = model.fit(\n",
    "#  train_inputs, train_targets,\n",
    "#  epochs= 1,\n",
    "#  batch_size = 500,\n",
    "#  validation_data = (train_validation_inputs, train_validation_targets)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
